{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import numpy as np\n",
    "import random\n",
    "import tank\n",
    "import truck\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import utilsq as ut\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368640"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_test_system(seed = None):\n",
    "    if seed != None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Tanks' information\n",
    "    global n\n",
    "    n = 5 \n",
    "    tank_ids = list(range(1,n+1))\n",
    "    tank_max_loads =  np.array([100., 100., 200., 300., 400.])\n",
    "    #tank_current_loads =  np.array([50., 60., 120., 150., 300.])\n",
    "    #tank_current_loads = tank_max_loads.copy()\n",
    "    tank_current_loads = np.full(n,0)\n",
    "    tank_consumption_rates =  np.array([5.] * n)\n",
    "    \n",
    "    global n_discrete_load_levels\n",
    "    n_discrete_load_levels = np.array([4,4,4,4,4])\n",
    "\n",
    "        \n",
    "    for i, (lvl, max_load) in enumerate(zip(n_discrete_load_levels, tank_max_loads)):\n",
    "        a = np.linspace(0,max_load, lvl+1)[1]\n",
    "        current_load = np.random.randint(a+1,max_load)\n",
    "        tank_current_loads[i] = current_load  \n",
    "\n",
    "    # Trucks' information\n",
    "    global k\n",
    "    k = 2\n",
    "    truck_ids = list(range(k))\n",
    "    truck_max_loads = np.array([20., 50.])\n",
    "    truck_current_loads = truck_max_loads.copy()\n",
    "    truck_current_positions =  np.array([5] * k)\n",
    "    #truck_fractions_deliverable =  np.array([1.] * k) # we for now we only allow to deliver all the content of the truck\n",
    "    truck_fractions_deliverable =  np.array([ np.array([1.]), \n",
    "                                              np.array([1.])\n",
    "                                            ]) # we for now we only allow to deliver all the content of the truck\n",
    "    global n_discrete_load_levels_trucks\n",
    "    n_discrete_load_levels_trucks = np.array([1,1])\n",
    "\n",
    "    # System's information\n",
    "   \n",
    "    graph = ut.simple_graph(n+1)\n",
    "    tanks = [tank.Tank( tank_id, current_load, max_load, consumption_rate, n_lvls) \n",
    "             for  tank_id, current_load, max_load, consumption_rate, n_lvls in \n",
    "             zip( tank_ids, tank_current_loads, tank_max_loads, tank_consumption_rates, n_discrete_load_levels)]\n",
    "    trucks = [truck.Truck( truck_id, current_load, max_load, current_position, load_fractions_deliverable, n_lvls) \n",
    "             for  truck_id, current_load, max_load, current_position, load_fractions_deliverable, n_lvls in \n",
    "             zip(truck_ids, truck_current_loads, truck_max_loads, truck_current_positions, \n",
    "                 truck_fractions_deliverable, n_discrete_load_levels_trucks)]\n",
    "\n",
    "    #w =  np.array([0, 20., 10., 30., 50.5, 45.])\n",
    "    w =  np.array([20., 20., 20., 20., 20., 0.])\n",
    "\n",
    "    weights_matrix = ut.simple_weights(n+1, w)\n",
    "    \n",
    "    return(tanks, trucks, graph, weights_matrix)\n",
    "\n",
    "tanks, trucks, graph, weights_matrix = initialize_test_system()\n",
    "toy_system = model.System(tanks = tanks, trucks = trucks, adjacency_matrix = graph, weights_matrix = weights_matrix)\n",
    "\n",
    "#print(toy_system.weights)\n",
    "\n",
    "a_s_dim = toy_system.states_dim * toy_system.actions_dim\n",
    "a_s_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 40, 157, 147, 289]\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1]]\n",
      "[[inf inf inf inf inf inf]\n",
      " [inf inf inf inf inf inf]\n",
      " [inf inf inf inf inf inf]\n",
      " [inf inf inf inf inf inf]\n",
      " [inf inf inf inf inf inf]\n",
      " [20. 20. 20. 20. 20.  0.]]\n"
     ]
    }
   ],
   "source": [
    "tanks, trucks, graph, weights_matrix = initialize_test_system(seed = 42)\n",
    "system = model.System(tanks = tanks, trucks = trucks, adjacency_matrix = graph, weights_matrix = weights_matrix)\n",
    "print(system.tank_loads())\n",
    "#print([load for load in system.tank_loads])\n",
    "print(system.graph)\n",
    "print(system.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 40, 157, 147, 289]\n",
      "[50.0, 29.0, 51.0, 97.0, 248.0]\n",
      "[72.0, 81.0, 180.0, 180.0, 188.0]\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "print(system.tank_loads())\n",
    "def reinitialize_system(system, seed = None):\n",
    "    if seed != None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    for tank, tank_levels in zip(system.tanks, system.tanks_level):\n",
    "        a = tank_levels[0]\n",
    "        b = tank_levels[-1]\n",
    "        current_load = np.random.randint(a+1,b)*1.0\n",
    "        tank.load = current_load\n",
    "    system.reset_trucks_positions(); \n",
    "    return(system)    \n",
    "\n",
    "system = reinitialize_system(system,3)\n",
    "print(system.tank_loads())\n",
    "system = reinitialize_system(system,4)\n",
    "print(system.tank_loads())\n",
    "reward = system.random_action(seed = 1, verbose = verbose)\n",
    "system.reset_trucks_positions();\n",
    "#print(reward)\n",
    "reward = system.random_action(seed = 1, verbose = verbose)\n",
    "#print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning algorithm (off-policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train parameters:\n",
    "retrain = False\n",
    "train_epsilon = True\n",
    "\n",
    "learning_rate0 = 0.05 #??\n",
    "learning_rate_decay = 0.1 #??\n",
    "\n",
    "episodes = 2*10**5 #episodes\n",
    "train_freq = 10**3\n",
    "episode_length = 50\n",
    "\n",
    "discount_rate = 1\n",
    "\n",
    "epsilon0 = 1.0\n",
    "epsilon_decay = (1./episodes) * 10\n",
    "epsilon_min = 0.05\n",
    "\n",
    "verbose = False\n",
    "verbose_info = False\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_visualization_steps = []\n",
    "train_rewards_list = []\n",
    "\n",
    "tanks, trucks, graph, weights_matrix = initialize_test_system()\n",
    "toy_system = model.System(tanks = tanks, trucks = trucks, adjacency_matrix = graph, weights_matrix = weights_matrix)\n",
    "\n",
    "Q = {}\n",
    "\n",
    "simulation_id = 11\n",
    "\n",
    "# if retrain == True:\n",
    "#     simulation_id_retrain = 3\n",
    "#     iteration_retrain = 50*10**6\n",
    "#     Q = ut.load_obj(\"Q-dict-sim\" + f\"{simulation_id_retrain}\" + \"-\" + f\"{iteration_retrain}\")\n",
    "\n",
    "ut.save_obj(toy_system, \"system-sim\"+f\"{simulation_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episodic_train_Q_epsilon( \n",
    "            epsilon0 = epsilon0,\n",
    "            epsilon_min = epsilon_min,\n",
    "            n_episodes = episodes, \n",
    "            episode_length = episode_length,\n",
    "            learning_rate0 = learning_rate0,\n",
    "            learning_rate_decay = learning_rate_decay,\n",
    "            discount_rate = discount_rate,\n",
    "            system = toy_system,\n",
    "            Q = Q, verbose = verbose, verbose_info = verbose_info,\n",
    "            visualization_steps = train_visualization_steps, rewards_list = train_rewards_list,\n",
    "            seed = seed, \n",
    "            freq = train_freq,\n",
    "            simulation_id = simulation_id,\n",
    "            round_time = 2\n",
    "           ):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    for episode in range(1,n_episodes+1):\n",
    "        reinitialize_system(system, seed = episode)\n",
    "        \n",
    "        ### epsilon-greedy exploration\n",
    "        epsilon = max( epsilon_min, epsilon0 / (1+(episode-1)*epsilon_decay) ) \n",
    "        \n",
    "        ### decrement of learning rate\n",
    "        learning_rate = learning_rate0 / (1+(episode-1)*learning_rate_decay)        \n",
    "\n",
    "        discounted_reward = 0\n",
    "        \n",
    "        for t in range(episode_length):\n",
    "\n",
    "            system.update_state()\n",
    "            s_current = system.state_to_string()                \n",
    "            p = np.random.uniform()\n",
    "\n",
    "            if p > epsilon:\n",
    "                #DETERMINISTIC ACTION OPTIMAL\n",
    "                s0 = system.state_to_string()\n",
    "                best_action = optimal_policy(s0, Q)\n",
    "                if best_action == None:\n",
    "                    reward = system.random_action(seed = (seed + (t+1)*episode), verbose = verbose)\n",
    "                else:\n",
    "                    reward = system.deterministic_action(best_action)\n",
    "                #print(best_action)\n",
    "            else:\n",
    "                reward = system.random_action(seed = (seed + (t+1)*episode), verbose = verbose)\n",
    "\n",
    "            a_current = system.action_to_string()\n",
    "            sa_current = ''.join([s_current, a_current])\n",
    "\n",
    "            system.update_state()\n",
    "            sa_new = system.state_action_to_string()\n",
    "\n",
    "            if ut.is_key(Q, sa_current) == False:\n",
    "                Q[sa_current] = 0\n",
    "\n",
    "            Q_max = max([Q[key] for key in Q.keys() if key.startswith(sa_new[0:system.state_length])]+[0.0]) \n",
    "\n",
    "            if Q[sa_current] != -np.inf:\n",
    "                Q[sa_current] = ( (1-learning_rate) * Q[sa_current] \n",
    "                                 + learning_rate* (reward + discount_rate * Q_max)\n",
    "                                )\n",
    "                \n",
    "            discounted_reward = discounted_reward + (discount_rate**t) * reward\n",
    "            system.reset_trucks_positions();     \n",
    "            system.reset_trucks_loads();\n",
    "            \n",
    "        rewards_list.append(discounted_reward);\n",
    "        if episode % freq == 0:\n",
    "                time_end = time.time()\n",
    "                print(\"Episode \", episode, \", Elapsed time \", round( (time_end-time_start)/60., round_time), \" minuts.\",\n",
    "                      \"epsilon\", round(epsilon,4), \n",
    "                     \"Discounted reward: \", discounted_reward)\n",
    "                \n",
    "                if verbose_info:\n",
    "                    print(\"s, a\", system.s, system.a)\n",
    "                    print(\"ds, da\", system.ds, system.da)\n",
    "\n",
    "                #Save visualization and rewards\n",
    "                visualization_steps.append(toy_system.visualize());    \n",
    "\n",
    "                ut.save_obj(Q, \"Q-dict-sim\" + f\"{simulation_id}\" + \"-\" + f\"{episode}\")   \n",
    "                ut.save_obj(visualization_steps, \"vis/vis-train-sim\" + f\"{simulation_id}\" + \"-\" + f\"{episode}\")   \n",
    "                #rewards_list.append(discounted_reward);\n",
    "                ut.save_obj(rewards_list, \"discrewards/discrew-train-sim\" + f\"{simulation_id}\" + \"-\" + f\"{episode}\")\n",
    "   \n",
    "    end_time = round(time.time()-time_start,round_time)        \n",
    "    print(f\"Training finished. Total episodes: {n_episodes}. Elapsed time: {round(end_time/60., round_time)} minuts.\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a state, returns the action that has the highest Q-value.\n",
    "\n",
    "def optimal_policy(state, Q, system = toy_system):\n",
    "    \"\"\"\n",
    "    state must be in the string-integers code\n",
    "    \"\"\"\n",
    "    state_keys = [key for key in list(Q) if key.startswith(state)]\n",
    "    if len(state_keys) == 0:\n",
    "        return(None)\n",
    "    \n",
    "    state_q = [Q[state_key] for state_key in state_keys]\n",
    "    \n",
    "    #print(\"state_q \", state_q[1:min(10,len(state_q))])\n",
    "    \n",
    "    max_q = max(state_q)\n",
    "    #print(\"max_q\", max_q)\n",
    "    optimal_key_index = np.where(np.isin(state_q, max_q ))[0][0]\n",
    "    #print(\"optimal_key_index\", optimal_key_index)\n",
    "    optimal_key = state_keys[optimal_key_index]\n",
    "    #print(\"optimal_key\", optimal_key)\n",
    "    optimal_action = optimal_key[system.state_length:]\n",
    "    \n",
    "    return(optimal_action)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  1000 , Elapsed time  1.27  minuts. epsilon 0.9524 Discounted reward:  -50283.000000000015\n",
      "Episode  2000 , Elapsed time  3.29  minuts. epsilon 0.9091 Discounted reward:  -37563.09999999999\n",
      "Episode  3000 , Elapsed time  5.75  minuts. epsilon 0.8696 Discounted reward:  -29639.8\n",
      "Episode  4000 , Elapsed time  8.5  minuts. epsilon 0.8334 Discounted reward:  -33306.6\n",
      "Episode  5000 , Elapsed time  11.49  minuts. epsilon 0.8 Discounted reward:  -27403.1\n",
      "Episode  6000 , Elapsed time  14.66  minuts. epsilon 0.7693 Discounted reward:  -29766.399999999998\n",
      "Episode  7000 , Elapsed time  18.02  minuts. epsilon 0.7408 Discounted reward:  -29066.6\n",
      "Episode  8000 , Elapsed time  21.54  minuts. epsilon 0.7143 Discounted reward:  -21306.399999999994\n",
      "Episode  9000 , Elapsed time  25.19  minuts. epsilon 0.6897 Discounted reward:  -21263.0\n",
      "Episode  10000 , Elapsed time  28.91  minuts. epsilon 0.6667 Discounted reward:  -19673.1\n",
      "Episode  11000 , Elapsed time  32.74  minuts. epsilon 0.6452 Discounted reward:  -23843.3\n",
      "Episode  12000 , Elapsed time  36.67  minuts. epsilon 0.625 Discounted reward:  -14209.900000000001\n",
      "Episode  13000 , Elapsed time  40.72  minuts. epsilon 0.6061 Discounted reward:  -24992.899999999998\n",
      "Episode  14000 , Elapsed time  44.86  minuts. epsilon 0.5883 Discounted reward:  -17129.9\n",
      "Episode  15000 , Elapsed time  49.08  minuts. epsilon 0.5714 Discounted reward:  -12766.5\n",
      "Episode  16000 , Elapsed time  53.39  minuts. epsilon 0.5556 Discounted reward:  -9080.0\n",
      "Episode  17000 , Elapsed time  57.77  minuts. epsilon 0.5406 Discounted reward:  -23852.899999999998\n",
      "Episode  18000 , Elapsed time  62.22  minuts. epsilon 0.5263 Discounted reward:  -18363.2\n",
      "Episode  19000 , Elapsed time  66.72  minuts. epsilon 0.5128 Discounted reward:  -15992.999999999996\n",
      "Episode  20000 , Elapsed time  71.3  minuts. epsilon 0.5 Discounted reward:  -12069.900000000001\n",
      "Episode  21000 , Elapsed time  75.95  minuts. epsilon 0.4878 Discounted reward:  -13633.2\n",
      "Episode  22000 , Elapsed time  80.65  minuts. epsilon 0.4762 Discounted reward:  -17846.5\n",
      "Episode  23000 , Elapsed time  85.43  minuts. epsilon 0.4651 Discounted reward:  -7363.2\n",
      "Episode  24000 , Elapsed time  90.22  minuts. epsilon 0.4546 Discounted reward:  -17703.3\n",
      "Episode  25000 , Elapsed time  95.08  minuts. epsilon 0.4445 Discounted reward:  -10163.3\n",
      "Episode  26000 , Elapsed time  99.97  minuts. epsilon 0.4348 Discounted reward:  -10223.3\n",
      "Episode  27000 , Elapsed time  104.93  minuts. epsilon 0.4255 Discounted reward:  -15260.0\n",
      "Episode  28000 , Elapsed time  109.94  minuts. epsilon 0.4167 Discounted reward:  -13866.6\n",
      "Episode  29000 , Elapsed time  114.99  minuts. epsilon 0.4082 Discounted reward:  -13236.599999999999\n",
      "Episode  30000 , Elapsed time  120.09  minuts. epsilon 0.4 Discounted reward:  -9996.400000000001\n",
      "Episode  31000 , Elapsed time  125.22  minuts. epsilon 0.3922 Discounted reward:  -10146.400000000001\n",
      "Episode  32000 , Elapsed time  130.38  minuts. epsilon 0.3846 Discounted reward:  -11200.0\n",
      "Episode  33000 , Elapsed time  135.57  minuts. epsilon 0.3774 Discounted reward:  -5403.3\n",
      "Episode  34000 , Elapsed time  140.81  minuts. epsilon 0.3704 Discounted reward:  -14559.699999999999\n",
      "Episode  35000 , Elapsed time  146.07  minuts. epsilon 0.3636 Discounted reward:  -13876.6\n",
      "Episode  36000 , Elapsed time  151.34  minuts. epsilon 0.3571 Discounted reward:  -14483.199999999997\n",
      "Episode  37000 , Elapsed time  156.65  minuts. epsilon 0.3509 Discounted reward:  -12906.599999999999\n",
      "Episode  38000 , Elapsed time  162.03  minuts. epsilon 0.3448 Discounted reward:  -13273.2\n",
      "Episode  39000 , Elapsed time  167.61  minuts. epsilon 0.339 Discounted reward:  -10666.599999999999\n",
      "Episode  40000 , Elapsed time  173.08  minuts. epsilon 0.3333 Discounted reward:  -8786.6\n",
      "Episode  41000 , Elapsed time  178.55  minuts. epsilon 0.3279 Discounted reward:  -8213.3\n",
      "Episode  42000 , Elapsed time  184.06  minuts. epsilon 0.3226 Discounted reward:  -9253.2\n",
      "Episode  43000 , Elapsed time  189.55  minuts. epsilon 0.3175 Discounted reward:  -10736.6\n",
      "Episode  44000 , Elapsed time  195.11  minuts. epsilon 0.3125 Discounted reward:  -10713.3\n",
      "Episode  45000 , Elapsed time  200.68  minuts. epsilon 0.3077 Discounted reward:  -14219.499999999996\n",
      "Episode  46000 , Elapsed time  206.27  minuts. epsilon 0.303 Discounted reward:  -8226.5\n",
      "Episode  47000 , Elapsed time  211.87  minuts. epsilon 0.2985 Discounted reward:  -6433.2\n",
      "Episode  48000 , Elapsed time  217.49  minuts. epsilon 0.2941 Discounted reward:  -10380.0\n",
      "Episode  49000 , Elapsed time  223.19  minuts. epsilon 0.2899 Discounted reward:  -12433.2\n",
      "Episode  50000 , Elapsed time  228.86  minuts. epsilon 0.2857 Discounted reward:  -8606.6\n",
      "Episode  51000 , Elapsed time  234.58  minuts. epsilon 0.2817 Discounted reward:  -7666.6\n",
      "Episode  52000 , Elapsed time  240.3  minuts. epsilon 0.2778 Discounted reward:  -8119.900000000001\n",
      "Episode  53000 , Elapsed time  246.02  minuts. epsilon 0.274 Discounted reward:  -8876.6\n",
      "Episode  54000 , Elapsed time  251.81  minuts. epsilon 0.2703 Discounted reward:  -9606.2\n",
      "Episode  55000 , Elapsed time  257.56  minuts. epsilon 0.2667 Discounted reward:  -5466.6\n",
      "Episode  56000 , Elapsed time  263.33  minuts. epsilon 0.2632 Discounted reward:  -8476.5\n",
      "Episode  57000 , Elapsed time  269.14  minuts. epsilon 0.2597 Discounted reward:  -7219.900000000001\n",
      "Episode  58000 , Elapsed time  274.97  minuts. epsilon 0.2564 Discounted reward:  -9613.3\n",
      "Episode  59000 , Elapsed time  280.81  minuts. epsilon 0.2532 Discounted reward:  -7699.8\n",
      "Episode  60000 , Elapsed time  286.65  minuts. epsilon 0.25 Discounted reward:  -7606.6\n",
      "Episode  61000 , Elapsed time  292.48  minuts. epsilon 0.2469 Discounted reward:  -5579.900000000001\n",
      "Episode  62000 , Elapsed time  298.31  minuts. epsilon 0.2439 Discounted reward:  -7246.400000000001\n",
      "Episode  63000 , Elapsed time  304.21  minuts. epsilon 0.241 Discounted reward:  -5263.3\n",
      "Episode  64000 , Elapsed time  310.07  minuts. epsilon 0.2381 Discounted reward:  -7636.6\n",
      "Episode  65000 , Elapsed time  315.94  minuts. epsilon 0.2353 Discounted reward:  -5789.900000000001\n",
      "Episode  66000 , Elapsed time  321.84  minuts. epsilon 0.2326 Discounted reward:  -7953.200000000001\n",
      "Episode  67000 , Elapsed time  327.77  minuts. epsilon 0.2299 Discounted reward:  -7786.6\n",
      "Episode  68000 , Elapsed time  333.69  minuts. epsilon 0.2273 Discounted reward:  -4716.6\n",
      "Episode  69000 , Elapsed time  339.64  minuts. epsilon 0.2247 Discounted reward:  -6203.200000000001\n",
      "Episode  70000 , Elapsed time  345.59  minuts. epsilon 0.2222 Discounted reward:  -10579.9\n",
      "Episode  71000 , Elapsed time  351.56  minuts. epsilon 0.2198 Discounted reward:  -6769.9\n",
      "Episode  72000 , Elapsed time  357.53  minuts. epsilon 0.2174 Discounted reward:  -9433.2\n",
      "Episode  73000 , Elapsed time  363.54  minuts. epsilon 0.2151 Discounted reward:  -7330.0\n",
      "Episode  74000 , Elapsed time  369.54  minuts. epsilon 0.2128 Discounted reward:  -9736.599999999999\n",
      "Episode  75000 , Elapsed time  375.54  minuts. epsilon 0.2105 Discounted reward:  -6113.200000000001\n",
      "Episode  76000 , Elapsed time  381.53  minuts. epsilon 0.2083 Discounted reward:  -3800.0\n",
      "Episode  77000 , Elapsed time  387.58  minuts. epsilon 0.2062 Discounted reward:  -7990.0\n",
      "Episode  78000 , Elapsed time  393.67  minuts. epsilon 0.2041 Discounted reward:  -7389.800000000001\n",
      "Episode  79000 , Elapsed time  399.74  minuts. epsilon 0.202 Discounted reward:  -6393.2\n",
      "Episode  80000 , Elapsed time  405.79  minuts. epsilon 0.2 Discounted reward:  -9603.3\n",
      "Episode  81000 , Elapsed time  411.97  minuts. epsilon 0.198 Discounted reward:  -3746.6000000000004\n",
      "Episode  82000 , Elapsed time  418.05  minuts. epsilon 0.1961 Discounted reward:  -8413.3\n",
      "Episode  83000 , Elapsed time  424.13  minuts. epsilon 0.1942 Discounted reward:  -4939.9\n",
      "Episode  84000 , Elapsed time  430.22  minuts. epsilon 0.1923 Discounted reward:  -5609.9\n",
      "Episode  85000 , Elapsed time  436.34  minuts. epsilon 0.1905 Discounted reward:  -8586.6\n",
      "Episode  86000 , Elapsed time  442.43  minuts. epsilon 0.1887 Discounted reward:  -5040.0\n",
      "Episode  87000 , Elapsed time  448.54  minuts. epsilon 0.1869 Discounted reward:  -7563.3\n",
      "Episode  88000 , Elapsed time  454.65  minuts. epsilon 0.1852 Discounted reward:  -7006.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  89000 , Elapsed time  460.79  minuts. epsilon 0.1835 Discounted reward:  -13099.900000000001\n",
      "Episode  90000 , Elapsed time  466.91  minuts. epsilon 0.1818 Discounted reward:  -7316.500000000001\n",
      "Episode  91000 , Elapsed time  473.06  minuts. epsilon 0.1802 Discounted reward:  -6249.9\n",
      "Episode  92000 , Elapsed time  479.24  minuts. epsilon 0.1786 Discounted reward:  -6279.9\n",
      "Episode  93000 , Elapsed time  485.42  minuts. epsilon 0.177 Discounted reward:  -8039.900000000001\n",
      "Episode  94000 , Elapsed time  491.61  minuts. epsilon 0.1754 Discounted reward:  -5089.900000000001\n",
      "Episode  95000 , Elapsed time  497.83  minuts. epsilon 0.1739 Discounted reward:  -10303.2\n",
      "Episode  96000 , Elapsed time  504.07  minuts. epsilon 0.1724 Discounted reward:  -8719.900000000001\n",
      "Episode  97000 , Elapsed time  510.27  minuts. epsilon 0.1709 Discounted reward:  -5093.2\n",
      "Episode  98000 , Elapsed time  516.48  minuts. epsilon 0.1695 Discounted reward:  -6809.900000000001\n",
      "Episode  99000 , Elapsed time  522.7  minuts. epsilon 0.1681 Discounted reward:  -6576.6\n",
      "Episode  100000 , Elapsed time  528.98  minuts. epsilon 0.1667 Discounted reward:  -9310.0\n",
      "Episode  101000 , Elapsed time  535.26  minuts. epsilon 0.1653 Discounted reward:  -6073.3\n",
      "Episode  102000 , Elapsed time  541.55  minuts. epsilon 0.1639 Discounted reward:  -6023.3\n",
      "Episode  103000 , Elapsed time  547.85  minuts. epsilon 0.1626 Discounted reward:  -7059.900000000001\n",
      "Episode  104000 , Elapsed time  554.12  minuts. epsilon 0.1613 Discounted reward:  -5656.6\n",
      "Episode  105000 , Elapsed time  560.41  minuts. epsilon 0.16 Discounted reward:  -6270.0\n",
      "Episode  106000 , Elapsed time  566.67  minuts. epsilon 0.1587 Discounted reward:  -5826.6\n",
      "Episode  107000 , Elapsed time  572.95  minuts. epsilon 0.1575 Discounted reward:  -8129.900000000001\n",
      "Episode  108000 , Elapsed time  579.28  minuts. epsilon 0.1563 Discounted reward:  -8809.900000000001\n",
      "Episode  109000 , Elapsed time  585.59  minuts. epsilon 0.155 Discounted reward:  -5609.8\n",
      "Episode  110000 , Elapsed time  591.92  minuts. epsilon 0.1538 Discounted reward:  -3320.0\n",
      "Episode  111000 , Elapsed time  598.25  minuts. epsilon 0.1527 Discounted reward:  -3290.0\n",
      "Episode  112000 , Elapsed time  604.59  minuts. epsilon 0.1515 Discounted reward:  -8636.6\n",
      "Episode  113000 , Elapsed time  610.98  minuts. epsilon 0.1504 Discounted reward:  -4256.6\n",
      "Episode  114000 , Elapsed time  617.32  minuts. epsilon 0.1493 Discounted reward:  -5639.900000000001\n",
      "Episode  115000 , Elapsed time  623.72  minuts. epsilon 0.1481 Discounted reward:  -5029.900000000001\n",
      "Episode  116000 , Elapsed time  630.07  minuts. epsilon 0.1471 Discounted reward:  -3049.9000000000005\n",
      "Episode  117000 , Elapsed time  636.43  minuts. epsilon 0.146 Discounted reward:  -5473.3\n",
      "Episode  118000 , Elapsed time  642.81  minuts. epsilon 0.1449 Discounted reward:  -5376.6\n",
      "Episode  119000 , Elapsed time  649.18  minuts. epsilon 0.1439 Discounted reward:  -4516.6\n",
      "Episode  120000 , Elapsed time  655.6  minuts. epsilon 0.1429 Discounted reward:  -4736.6\n",
      "Episode  121000 , Elapsed time  662.03  minuts. epsilon 0.1418 Discounted reward:  -8203.2\n",
      "Episode  122000 , Elapsed time  668.44  minuts. epsilon 0.1408 Discounted reward:  -5980.0\n",
      "Episode  123000 , Elapsed time  674.83  minuts. epsilon 0.1399 Discounted reward:  -4716.6\n",
      "Episode  124000 , Elapsed time  681.24  minuts. epsilon 0.1389 Discounted reward:  -5183.2\n",
      "Episode  125000 , Elapsed time  687.7  minuts. epsilon 0.1379 Discounted reward:  -5536.6\n",
      "Episode  126000 , Elapsed time  694.1  minuts. epsilon 0.137 Discounted reward:  -4169.9\n",
      "Episode  127000 , Elapsed time  700.55  minuts. epsilon 0.1361 Discounted reward:  -6476.5\n",
      "Episode  128000 , Elapsed time  706.96  minuts. epsilon 0.1351 Discounted reward:  -6273.200000000001\n",
      "Episode  129000 , Elapsed time  713.39  minuts. epsilon 0.1342 Discounted reward:  -3636.6000000000004\n",
      "Episode  130000 , Elapsed time  719.83  minuts. epsilon 0.1333 Discounted reward:  -5796.6\n",
      "Episode  131000 , Elapsed time  726.29  minuts. epsilon 0.1325 Discounted reward:  -6416.5\n",
      "Episode  132000 , Elapsed time  732.77  minuts. epsilon 0.1316 Discounted reward:  -3506.6000000000004\n",
      "Episode  133000 , Elapsed time  739.27  minuts. epsilon 0.1307 Discounted reward:  -3523.3\n",
      "Episode  134000 , Elapsed time  745.77  minuts. epsilon 0.1299 Discounted reward:  -2980.0\n",
      "Episode  135000 , Elapsed time  752.28  minuts. epsilon 0.129 Discounted reward:  -9033.2\n",
      "Episode  136000 , Elapsed time  758.77  minuts. epsilon 0.1282 Discounted reward:  -5386.6\n",
      "Episode  137000 , Elapsed time  765.28  minuts. epsilon 0.1274 Discounted reward:  -3963.2\n",
      "Episode  138000 , Elapsed time  771.79  minuts. epsilon 0.1266 Discounted reward:  -4310.0\n",
      "Episode  139000 , Elapsed time  778.27  minuts. epsilon 0.1258 Discounted reward:  -5243.3\n",
      "Episode  140000 , Elapsed time  784.77  minuts. epsilon 0.125 Discounted reward:  -2330.0\n",
      "Episode  141000 , Elapsed time  791.21  minuts. epsilon 0.1242 Discounted reward:  -6353.3\n",
      "Episode  142000 , Elapsed time  797.74  minuts. epsilon 0.1235 Discounted reward:  -3156.6000000000004\n",
      "Episode  143000 , Elapsed time  804.25  minuts. epsilon 0.1227 Discounted reward:  -7273.200000000001\n",
      "Episode  144000 , Elapsed time  810.78  minuts. epsilon 0.122 Discounted reward:  -5669.8\n",
      "Episode  145000 , Elapsed time  817.31  minuts. epsilon 0.1212 Discounted reward:  -8193.2\n",
      "Episode  146000 , Elapsed time  823.78  minuts. epsilon 0.1205 Discounted reward:  -1980.0\n",
      "Episode  147000 , Elapsed time  830.33  minuts. epsilon 0.1198 Discounted reward:  -4899.900000000001\n",
      "Episode  148000 , Elapsed time  836.85  minuts. epsilon 0.119 Discounted reward:  -3003.2\n",
      "Episode  149000 , Elapsed time  843.36  minuts. epsilon 0.1183 Discounted reward:  -5476.6\n",
      "Episode  150000 , Elapsed time  849.89  minuts. epsilon 0.1176 Discounted reward:  -2483.3\n",
      "Episode  151000 , Elapsed time  856.46  minuts. epsilon 0.117 Discounted reward:  -3293.3\n",
      "Episode  152000 , Elapsed time  863.0  minuts. epsilon 0.1163 Discounted reward:  -2456.6\n",
      "Episode  153000 , Elapsed time  869.53  minuts. epsilon 0.1156 Discounted reward:  -2450.0\n",
      "Episode  154000 , Elapsed time  876.05  minuts. epsilon 0.1149 Discounted reward:  -6536.500000000001\n",
      "Episode  155000 , Elapsed time  882.61  minuts. epsilon 0.1143 Discounted reward:  -6779.900000000001\n",
      "Episode  156000 , Elapsed time  889.13  minuts. epsilon 0.1136 Discounted reward:  -5596.6\n",
      "Episode  157000 , Elapsed time  895.73  minuts. epsilon 0.113 Discounted reward:  -5759.900000000001\n",
      "Episode  158000 , Elapsed time  902.32  minuts. epsilon 0.1124 Discounted reward:  -4323.3\n",
      "Episode  159000 , Elapsed time  908.93  minuts. epsilon 0.1117 Discounted reward:  -4373.3\n",
      "Episode  160000 , Elapsed time  915.51  minuts. epsilon 0.1111 Discounted reward:  -3019.9\n",
      "Episode  161000 , Elapsed time  922.12  minuts. epsilon 0.1105 Discounted reward:  -3556.6\n",
      "Episode  162000 , Elapsed time  928.69  minuts. epsilon 0.1099 Discounted reward:  -5213.3\n",
      "Episode  163000 , Elapsed time  935.32  minuts. epsilon 0.1093 Discounted reward:  -4000.0\n",
      "Episode  164000 , Elapsed time  941.98  minuts. epsilon 0.1087 Discounted reward:  -3519.9000000000005\n",
      "Episode  165000 , Elapsed time  948.65  minuts. epsilon 0.1081 Discounted reward:  -5439.700000000001\n",
      "Episode  166000 , Elapsed time  955.26  minuts. epsilon 0.1075 Discounted reward:  -2859.9\n",
      "Episode  167000 , Elapsed time  961.88  minuts. epsilon 0.107 Discounted reward:  -7170.0\n",
      "Episode  168000 , Elapsed time  968.56  minuts. epsilon 0.1064 Discounted reward:  -2646.6\n",
      "Episode  169000 , Elapsed time  975.22  minuts. epsilon 0.1058 Discounted reward:  -3829.9\n",
      "Episode  170000 , Elapsed time  981.88  minuts. epsilon 0.1053 Discounted reward:  -7689.8\n",
      "Episode  171000 , Elapsed time  988.51  minuts. epsilon 0.1047 Discounted reward:  -4263.3\n",
      "Episode  172000 , Elapsed time  995.13  minuts. epsilon 0.1042 Discounted reward:  -4999.8\n",
      "Episode  173000 , Elapsed time  1001.78  minuts. epsilon 0.1036 Discounted reward:  -2286.6\n",
      "Episode  174000 , Elapsed time  1008.41  minuts. epsilon 0.1031 Discounted reward:  -2293.3\n",
      "Episode  175000 , Elapsed time  1015.04  minuts. epsilon 0.1026 Discounted reward:  -3326.6\n",
      "Episode  176000 , Elapsed time  1021.77  minuts. epsilon 0.102 Discounted reward:  -6759.800000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  177000 , Elapsed time  1028.37  minuts. epsilon 0.1015 Discounted reward:  -4593.3\n",
      "Episode  178000 , Elapsed time  1035.03  minuts. epsilon 0.101 Discounted reward:  -4739.9\n",
      "Episode  179000 , Elapsed time  1041.72  minuts. epsilon 0.1005 Discounted reward:  -2203.3\n",
      "Episode  180000 , Elapsed time  1048.39  minuts. epsilon 0.1 Discounted reward:  -3719.9000000000005\n",
      "Episode  181000 , Elapsed time  1055.07  minuts. epsilon 0.0995 Discounted reward:  -4509.8\n",
      "Episode  182000 , Elapsed time  1061.71  minuts. epsilon 0.099 Discounted reward:  -6380.0\n",
      "Episode  183000 , Elapsed time  1068.38  minuts. epsilon 0.0985 Discounted reward:  -3446.6\n",
      "Episode  184000 , Elapsed time  1075.04  minuts. epsilon 0.098 Discounted reward:  -4343.3\n",
      "Episode  185000 , Elapsed time  1081.67  minuts. epsilon 0.0976 Discounted reward:  -5119.900000000001\n",
      "Episode  186000 , Elapsed time  1088.32  minuts. epsilon 0.0971 Discounted reward:  -5926.6\n",
      "Episode  187000 , Elapsed time  1094.98  minuts. epsilon 0.0966 Discounted reward:  -9103.2\n",
      "Episode  188000 , Elapsed time  1101.67  minuts. epsilon 0.0962 Discounted reward:  -5759.900000000001\n",
      "Episode  189000 , Elapsed time  1108.35  minuts. epsilon 0.0957 Discounted reward:  -9366.5\n",
      "Episode  190000 , Elapsed time  1115.01  minuts. epsilon 0.0952 Discounted reward:  -4103.200000000001\n",
      "Episode  191000 , Elapsed time  1121.68  minuts. epsilon 0.0948 Discounted reward:  -5426.6\n",
      "Episode  192000 , Elapsed time  1128.34  minuts. epsilon 0.0943 Discounted reward:  -4880.0\n",
      "Episode  193000 , Elapsed time  1135.02  minuts. epsilon 0.0939 Discounted reward:  -3243.3\n",
      "Episode  194000 , Elapsed time  1141.69  minuts. epsilon 0.0935 Discounted reward:  -5426.500000000001\n",
      "Episode  195000 , Elapsed time  1148.37  minuts. epsilon 0.093 Discounted reward:  -4353.3\n",
      "Episode  196000 , Elapsed time  1155.06  minuts. epsilon 0.0926 Discounted reward:  -6699.8\n",
      "Episode  197000 , Elapsed time  1161.72  minuts. epsilon 0.0922 Discounted reward:  -3809.8999999999996\n",
      "Episode  198000 , Elapsed time  1168.42  minuts. epsilon 0.0917 Discounted reward:  -3070.0\n",
      "Episode  199000 , Elapsed time  1175.14  minuts. epsilon 0.0913 Discounted reward:  -4273.2\n",
      "Episode  200000 , Elapsed time  1181.86  minuts. epsilon 0.0909 Discounted reward:  -5606.6\n",
      "Training finished. Total episodes: 200000. Elapsed time: 1181.87 minuts.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9512d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train_epsilon == True:\n",
    "    #train_Q_epsilon()\n",
    "    episodic_train_Q_epsilon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST PARAMETERS AND INITIALIZATION\n",
    "\n",
    "# Initialize system\n",
    "tanks, trucks, graph, weights_matrix = initialize_test_system(seed = 42)\n",
    "test_toy_system = model.System(tanks = tanks, trucks = trucks, adjacency_matrix = graph, weights_matrix = weights_matrix)\n",
    "\n",
    "#Load trained Q-values\n",
    "# if train == False:\n",
    "#     simulation_id = 8\n",
    "#     train_iterations = 20*10**5\n",
    "#     test_toy_system = ut.load_obj(\"system-sim\"+ f\"{simulation_id}\")\n",
    "#     Q = ut.load_obj(\"Q-dict-sim\" + f\"{simulation_id}\" + \"-\" + f\"{train_iterations}\")\n",
    "\n",
    "\n",
    "# if retrain == False:\n",
    "#     simulation_id = 7\n",
    "#     train_iterations = 259*10**6\n",
    "#     test_toy_system = ut.load_obj(\"system-sim\"+ f\"{simulation_id}\")    \n",
    "#     Q = ut.load_obj(\"Q-dict-sim\" + f\"{simulation_id}\" + \"-\" + f\"{train_iterations}\")\n",
    "\n",
    "   \n",
    "#test_toy_system = ut.load_obj(\"system-sim\"+ f\"{simulation_id}\")    \n",
    "Q = ut.load_obj(\"Q-dict-sim\" + f\"{simulation_id}\" + \"-\" + f\"{episodes}\")\n",
    "\n",
    "\n",
    "test_episodes = 2\n",
    "episode_length = 100\n",
    "test_freq = 1\n",
    "test_verbose = False\n",
    "\n",
    "test_visualization_steps = []\n",
    "test_rewards_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Q(n_episodes = test_episodes, \n",
    "           episode_length = episode_length,\n",
    "           system = test_toy_system,\n",
    "           visualization_steps = test_visualization_steps, \n",
    "           rewards_list = test_rewards_list,\n",
    "           freq = test_freq,\n",
    "           test_verbose = test_verbose\n",
    "           \n",
    "          ):\n",
    "    \n",
    "    for episode in range(1,n_episodes+1): \n",
    "\n",
    "        discounted_reward = 0      \n",
    "        \n",
    "        for i in range(1,episode_length+1):\n",
    "            #print(\"state\", test_toy_system.s, test_toy_system.ds)\n",
    "            system.update_state()\n",
    "\n",
    "            #Save visualization steps\n",
    "            if i % freq == 0:\n",
    "                visualization_steps.append(system.visualize());\n",
    "\n",
    "            s0 = system.state_to_string()\n",
    "            best_action = optimal_policy(s0, Q)\n",
    "            #print(\"best_action\", best_action)\n",
    "\n",
    "            if best_action == None:\n",
    "                reward = system.random_action()\n",
    "                if i % freq == 0:\n",
    "                    if test_verbose == True:\n",
    "                        print(\"Episode\", episode, \"t\", i-1, reward, \" Random action is performed. Current state unknown for Q.\")\n",
    "\n",
    "            else:\n",
    "                reward = system.deterministic_action(best_action)\n",
    "                if i % freq == 0:\n",
    "                    if test_verbose == True:\n",
    "                        print(\"Episode\", episode, \"t\",i-1,reward, best_action)\n",
    "\n",
    "            system.reset_trucks_positions();\n",
    "            system.reset_trucks_loads();\n",
    "            \n",
    "            discounted_reward = discounted_reward + (discount_rate**(i-1)) * reward\n",
    "\n",
    "        system.reset_trucks_positions();\n",
    "        \n",
    "        #Save rewards\n",
    "        if episode % freq == 0:\n",
    "                rewards_list.append(discounted_reward);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9a351d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_Q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d2df8c8b6b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualizing test simulation:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_anim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_system_animation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_visualization_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_episodes\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepisode_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_anim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_html5_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mto_html5_video\u001b[1;34m(self, embed_limit)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 \u001b[1;31m# We create a writer manually so that we can get the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m                 \u001b[1;31m# appropriate size for the tag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m                 \u001b[0mWriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwriters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'animation.writer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m                 writer = Writer(codec='h264',\n\u001b[0;32m   1411\u001b[0m                                 \u001b[0mbitrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'animation.bitrate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No MovieWriters available!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavail\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[0mwriters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMovieWriterRegistry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ffmpeg'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd63198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing test simulation:\n",
    "test_anim = ut.create_system_animation(test_visualization_steps, test_episodes * episode_length,test_freq)\n",
    "HTML(test_anim.to_html5_video())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.plot([i for i in range(len(test_rewards_list))], test_rewards_list)\n",
    "print(test_rewards_list)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing train simulation:\n",
    "\n",
    "# train_anim = ut.create_system_animation(train_visualization_steps, train_iterations, train_freq)\n",
    "# HTML(train_anim.to_html5_video())\n",
    "\n",
    "episode = episodes\n",
    "discrewards_list = ut.load_obj(\"discrewards/discrew-train-sim\" + f\"{simulation_id}\" + \"-\" + f\"{episode}\")\n",
    "p = plt.plot([i for i in range(len(discrewards_list))], discrewards_list)\n",
    "#print(discrewards_list)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # simulation_id = 4\n",
    "    #train_iterations = 2*10**6\n",
    "    #test_toy_system = ut.load_obj(\"system-sim\"+ f\"{simulation_id}\")    \n",
    "    #Q = ut.load_obj(\"Q-dict-sim\" + f\"{simulation_id}\" + \"-\" + f\"{train_iterations}\")\n",
    "\n",
    "len(list(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
